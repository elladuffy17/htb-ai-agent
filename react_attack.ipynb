{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTB ReAct Agent\n",
    "- **Author**: Ella Duffy\n",
    "- **Version**: 1.0.0\n",
    "- **Description**: Implements a ReAct (Reasoning + Action + Observation) agent for HTB pentesting using LangGraph. This agent uses existing tools from `ssh_command_executor.py` to perform port scanning, user enumeration, and SSH port detection, with plans for brute-forcing and input sanitization.\n",
    "\n",
    "## Objective\n",
    "- Automate HTB attack chaining with a stateful, reasoning-based agent.\n",
    "- Leverage `scan_ports`, `enumerate_users`, and `detect_ssh_port` and `ssh_execute_command` tools.\n",
    "- Prepare for future enhancements like brute-forcing and safety checks.\n",
    "\n",
    "## Prerequisites\n",
    "- Parrot OS VM (e.g., `10.0.0.215`) with HTB VPN active.\n",
    "- `ssh_command_executor.py` in the working directory.\n",
    "- OpenAI API key set in `~/Ella_AI/.env` as `OPENAI_API_KEY`.\n",
    "\n",
    "## Overview of ReAct Framework Implementation\n",
    "This HTB ReAct agent is designed based on the **ReAct (Reasoning + Acting)** framework, which synergizes step-by-step reasoning with action execution to solve complex tasks. Here's how it aligns:\n",
    "\n",
    "- **Reasoning**: The agent uses a custom prompt template that instructs the language model (e.g., `gpt-4o-mini`) to think step-by-step, analyzing the task, current state, previous results, and memory to decide the next action. The \"Let's think step by step\" directive encourages deliberate planning.\n",
    "\n",
    "- **Acting**: The agent leverages a set of tools (`scan_ports`, `enumerate_users`, `detect_ssh_port`, `ssh_execute_command`) integrated via LangGraph's `create_react_agent`. These tools allow the agent to interact with the HTB environment (e.g., scanning ports or executing SSH commands) based on its reasoning.\n",
    "\n",
    "- **Observation**: Results from tool executions are stored in the `AgentState` (`result` field) and memory (`ChatMessageHistory`), enabling the agent to observe outcomes and refine its approach. The state graph's transitions (e.g., from `ports_scanned` to `enumerate_users`) facilitate this iterative process.\n",
    "\n",
    "- **Iteration**: The agent repeats the reason-act-observe cycle, guided by the `next_step` function, until the task (e.g., reconnaissance and command execution) is complete, aligning with ReAct's iterative nature.\n",
    "\n",
    "- **Implementation Approach**: Initially, the agent uses a hardcoded `StateGraph` with predefined nodes and transitions to ensure a reliable workflow for pentesting tasks. However, the development is moving toward a more dynamic approach, where the language model will drive tool selection and action sequences autonomously using a `ToolExecutor`, reducing reliance on fixed graph structures for greater adaptability.\n",
    "\n",
    "This hybrid approach balances reliability with flexibility, with future enhancements planned to fully embrace the dynamic ReAct paradigm.\n",
    "\n",
    "![ReAct Framework](images/react.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 21:37:18,258 - INFO - Loading SSH Command Executor\n",
      "2025-07-08 21:37:18,275 - INFO - Loading HTB ReAct Agent\n",
      "2025-07-08 21:37:18,276 - INFO - API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "#Imports and setup\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.agents import Tool\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from ssh_command_executor import Tools #my defined Tools class\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/react_attack.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"Loading HTB ReAct Agent\")\n",
    "\n",
    "# Load API key from environment\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment. Set it in .env or export it manually.\")\n",
    "logger.info(\"API key loaded successfully\")\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, api_key=api_key)\n",
    "\n",
    "# Initialize memory\n",
    "memory = ChatMessageHistory()\n",
    "\n",
    "# Initialize my defined Tools that are imported from ssh_command_executor\n",
    "tools = Tools(memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define tools for the agent\n",
    "tools_list = [\n",
    "    Tool(\n",
    "        name=\"ssh_execute_command\",\n",
    "        func=lambda host, username, command: tools.ssh_command_executor(host, username, command),\n",
    "        description=\"Execute a custom SSH command on the target HTB machine. Args: host (str), username (str), command (str)\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"scan_ports\",\n",
    "        func=lambda host, username, target: tools.scan_ports(host, username, target),\n",
    "        description=\"Scan open ports on the target HTB machine and return a dictionary of port:service pairs. Args: host (str), username (str), target (str)\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"enumerate_users\",\n",
    "        func=lambda host, username, target: tools.enumerate_users(host, username, target),\n",
    "        description=\"Enumerate SSH users on the target HTB machine if finger service (port 79) is available. Args: host (str), username (str), target (str)\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"detect_ssh_port\",\n",
    "        func=lambda host, username, target: tools.detect_ssh_port(host, username, target),\n",
    "        description=\"Detect the SSH port on the target HTB machine using memory-based analysis. Args: host (str), username (str), target (str)\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    memory: str\n",
    "    result: Annotated[list, operator.add]\n",
    "    current_step: str\n",
    "    host: str\n",
    "    username: str\n",
    "    target: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ReAct prompot template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are an AI assistance for Hack The Box pentesting. Use the provided tools to perform taks on the HTB target.\n",
    "    Follow this process:\n",
    "    1. Reason about the task and decide which tool(s) to use based on the current state and previous results.\n",
    "    2. Take action by calling the appropriate tool with the correct arguments.\n",
    "    3. Observe the result and decide the next step, repeating if necessary, or use ssh_execute_command for custom actions.\n",
    "    4. Return the final result when the task is complete.\n",
    "\n",
    "    Tools available: {tool_names}\n",
    "\n",
    "    Task: {task}\n",
    "\n",
    "    Previous conversation: {memory}\n",
    "\n",
    "    Current state: {current_step}\n",
    "    Previous results: {result}\n",
    "\n",
    "    Reasoning: Let's think step by step:\n",
    "    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ReAct agent\n",
    "agent = create_react_agent(\n",
    "    model=llm, \n",
    "    tools=tools_list, \n",
    "    prompt=prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the state graph\n",
    "\n",
    "def scan_ports_node(state: AgentState):\n",
    "    logger.info(f\"Executing scan_ports on {state['target']}\")\n",
    "    result = tools.scan_ports(state['host'], state['username'], state['target']) #returns dictionary of port:service pairs\n",
    "    return {\"result\": [result], \"current_step\": \"ports_scanned\"}\n",
    "\n",
    "def enumerate_users_node(state: AgentState):\n",
    "    logger.info(f\"Executing enumerate_users on {state['target']}\")\n",
    "    if \"79\" in state[\"result\"][-1]:\n",
    "        result = tools.enumerate_users(state['host'], state['username'], state['target'])\n",
    "        return {\"result\": state[\"result\"] + [result], \"current_step\": \"users_enumerated\"}\n",
    "    return {\"result\": state[\"result\"], \"current_step\": \"users_skipped\"}\n",
    "\n",
    "def detect_ssh_port_node(state: AgentState):\n",
    "    logger.info(f\"Executing detect_ssh_port on {state['target']}\")\n",
    "    result = tools.detect_ssh_port(state['host'], state['username'], state['target'])\n",
    "    return {\"result\": state[\"result\"] + [result], \"current_step\": \"ssh_detected\"}\n",
    "\n",
    "def execute_command_node(state: AgentState):\n",
    "    logger.info(f\"Executing ssh_execute_command on {state['target']}\")\n",
    "    # Allow LLM to decide the command via reasoning\n",
    "    result = tools.ssh_command_executor(state['host'], state['username'], \"whoami\") # Default command, LLM can override\n",
    "    return {\"result\": state[\"result\"] + [result], \"current_step\": \"command_executed\"}\n",
    "\n",
    "# Define conditional transitions\n",
    "def next_step(state: AgentState):\n",
    "    if state[\"current_step\"] == \"command_executed\":\n",
    "        return END\n",
    "    if state[\"current_step\"] == \"ports_scanned\":\n",
    "        return \"enumerate_users\"\n",
    "    if state[\"current_step\"] == \"users_enumerated\" or state[\"current_step\"] == \"users_skipped\":\n",
    "        return \"detect_ssh_port\"\n",
    "    if state[\"current_step\"] == \"ssh_detected\":\n",
    "        return \"execute_command\"\n",
    "    return \"scan_ports\"  # Fallback to start\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"scan_ports\", scan_ports_node)\n",
    "graph.add_node(\"enumerate_users\", enumerate_users_node)\n",
    "graph.add_node(\"detect_ssh_port\", detect_ssh_port_node)\n",
    "graph.add_node(\"execute_command\", execute_command_node)\n",
    "\n",
    "graph.set_entry_point(\"scan_ports\")\n",
    "graph.add_conditional_edges(\"scan_ports\", next_step)\n",
    "graph.add_conditional_edges(\"enumerate_users\", next_step)\n",
    "graph.add_conditional_edges(\"detect_ssh_port\", next_step)\n",
    "graph.add_conditional_edges(\"execute_command\", next_step)\n",
    "\n",
    "app = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple task function\n",
    "def run_react_agent(host, username, target):\n",
    "    logger.info(f\"Starting ReAct agent on {target} via {host}\")\n",
    "    initial_state = {\n",
    "        \"task\": f\"Perform reconnaissance on the HTB target {target} by scanning ports, enumerating users if possible, detecting the SSH port, and running a custom command. Use ssh_execute_command to explore further if needed.\",\n",
    "        \"memory\": \"\\n\".join(msg[\"content\"] for msg in memory.messages if \"content\" in msg), #ensure we are working with human-readable string representation\n",
    "        \"result\": [],\n",
    "        \"current_step\": \"start\",\n",
    "        \"host\": host,\n",
    "        \"username\": username,\n",
    "        \"target\": target\n",
    "    }\n",
    "    result = app.invoke(initial_state)\n",
    "    logger.info(f\"ReAct agent completed: {result['result']}\")\n",
    "    return result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Agent\n",
    "if __name__ == \"__main__\":\n",
    "    host = \"10.0.0.215\"\n",
    "    username = \"user\"\n",
    "    target = \"10.10.10.76\"\n",
    "    result = run_react_agent(host, username, target)\n",
    "    print(\"Final result:\", result)\n",
    "\n",
    "    # Debug memory\n",
    "    print(\"Memory content:\", \"\\n\".join(msg[\"content\"] for msg in memory.messages if \"content\" in msg)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
